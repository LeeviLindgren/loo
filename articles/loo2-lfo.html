<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Approximate leave-future-out cross-validation for time series models • loo</title>
<link rel="shortcut icon" type="image/x-icon" href="../favicon.ico">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.1/clipboard.min.js" integrity="sha256-hIvIxeqhGZF+VVeM55k0mJvWpQ6gTkWk3Emc+NmowYA=" crossorigin="anonymous"></script><!-- sticky kit --><script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Approximate leave-future-out cross-validation for time series models">
<meta property="og:description" content="">
<meta property="og:image" content="/logo.png">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">loo</a>
        <span class="label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">2.0.0.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../articles/index.html">Vignettes</a>
</li>
<li>
  <a href="../reference/index.html">Functions</a>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Other Packages
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="http://mc-stan.org/rstan">rstan</a>
    </li>
    <li>
      <a href="http://mc-stan.org/rstanarm">rstanarm</a>
    </li>
    <li>
      <a href="http://mc-stan.org/bayesplot">bayesplot</a>
    </li>
    <li>
      <a href="http://mc-stan.org/shinystan">shinystan</a>
    </li>
    <li>
      <a href="http://mc-stan.org/projpred">projpred</a>
    </li>
    <li>
      <a href="http://mc-stan.org/rstantools">rstantools</a>
    </li>
  </ul>
</li>
<li>
  <a href="http://mc-stan.org">Stan</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://twitter.com/mcmc_stan">
    <span class="fa fa-twitter"></span>
     
  </a>
</li>
<li>
  <a href="https://github.com/stan-dev/loo">
    <span class="fa fa-github"></span>
     
  </a>
</li>
<li>
  <a href="http://discourse.mc-stan.org/">
    <span class="fa fa-users"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Approximate leave-future-out cross-validation for time series models</h1>
                        <h4 class="author">Paul Bürkner, Aki Vehtari, Jonah Gabry</h4>
            
            <h4 class="date">2018-10-17</h4>
      
      
      <div class="hidden name"><code>loo2-lfo.Rmd</code></div>

    </div>

    
    
<!--
%\VignetteEngine{knitr::rmarkdown}
%\VignetteIndexEntry{Approximate leave-future-out cross-validation for time series models}
-->
<div id="introduction" class="section level2">
<h2 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h2>
<p>One of the most common goals of a time series analysis is to use the observed series to inform predictions for future observations. We will refer to this task of predicting a sequence of <span class="math inline">\(M\)</span> future observations as <span class="math inline">\(M\)</span>-step-ahead prediction (<span class="math inline">\(M\)</span>-SAP). Fortunately, once we have fit a model and can sample from the posterior predictive distribution, it is straightforward to generate predictions as far into the future as we want. It is also straightforward to evaluate the <span class="math inline">\(M\)</span>-SAP performance of a time series model by comparing the predictions to the observed sequence of <span class="math inline">\(M\)</span> future data points once they become available.</p>
<p>Unfortunately, we are often in the position of having to use a model to inform decisions <em>before</em> we can collect the future observations required for assessing the predictive performance. If we have many competing models we may also need to first decide which of the models (or which combination of the models) we should rely on for predictions. In these situations the best we can do is to use methods for approximating the expected predictive performance of our models using only the observations of the time series we already have.</p>
<p>If there were no time dependence in the data or if the focus is to assess the non-time-dependent part of the model, we could use methods like leave-one-out cross-validation (LOO-CV). For a data set with <span class="math inline">\(N\)</span> observations, we refit the model <span class="math inline">\(N\)</span> times, each time leaving out one of the <span class="math inline">\(N\)</span> observations and assessing how well the model predicts the left-out observation. LOO-CV is very expensive computationally in most realistic settings, but the Pareto smoothed importance sampling (PSIS, Vehtari et al, 2017ab) algorithm provided by the <em>loo</em> package allows for approximating exact LOO-CV with PSIS-LOO-CV. PSIS-LOO-CV requires only a single fit of the full model and comes with diagnostics for assessing the validity of the approximation.</p>
<p>With a time series we can do something similar to LOO-CV but, except in a few cases, it does not make sense to leave out observations one at a time because then we are allowing information from the future to influence predictions of the past (i.e., times <span class="math inline">\(t + 1, t+2, \ldots\)</span> should not be used to predict for time <span class="math inline">\(t\)</span>). To apply the idea of cross-validation to the <span class="math inline">\(M\)</span>-SAP case, instead of leave-<em>one</em>-out cross-validation we need some form of leave-<em>future</em>-out cross-validation (LFO-CV). As we will demonstrate in this case study, LFO-CV does not refer to one particular prediction task but rather to various possible cross-validation approaches that all involve some form of prediction for new time series data. Like exact LOO-CV, exact LFO-CV requires refitting the model many times to different subsets of the data, which is computationally very costly for most nontrivial examples, in particular for Bayesian analyses where refitting the model means estimating a new posterior distribution rather than a point estimate.</p>
<p>Although PSIS-LOO-CV provides an efficient approximation to exact LOO-CV, until now there has not been an analogous approximation to exact LFO-CV that drastically reduces the computational burden while also providing informative diagnostics about the quality of the approximation. In this case study we present PSIS-LFO-CV, an algorithm that typically only requires refitting the time-series model a small number times and will make LFO-CV tractable for many more realistic applications than previously possible.</p>
</div>
<div id="m-step-ahead-predictions" class="section level2">
<h2 class="hasAnchor">
<a href="#m-step-ahead-predictions" class="anchor"></a><span class="math inline">\(M\)</span>-step-ahead predictions</h2>
<p>Assume we have a time series of observations <span class="math inline">\(\mathbf{y} = (y_1, y_2, \ldots, y_N)\)</span> and let <span class="math inline">\(L\)</span> be the <em>minimum</em> number of observations from the series that we will require before making predictions for future data. Depending on the application and how informative the data is, it may not be possible to make reasonable predictions for <span class="math inline">\(y_{i}\)</span> based on <span class="math inline">\((y_1, \dots, y_{i-1})\)</span> until <span class="math inline">\(i\)</span> is large enough so that we can learn enough about the time series to predict future observations. Setting <span class="math inline">\(L=10\)</span>, for example, means that we will only assess predictive performance starting with observation <span class="math inline">\(y_{11}\)</span>, so that we always have at least 10 previous observations to condition on.</p>
<p>In order to assess <span class="math inline">\(M\)</span>-SAP performance we would like to compute the predictive densities</p>
<p><span class="math display">\[
p(y_{i&lt;M} \,|\, y_{&lt;i}) = p(y_i, \ldots, y_{i + M - 1} \,|\, y_{1},...,y_{i-1}) 
\]</span></p>
<p>for each <span class="math inline">\(i \in \{L + 1, \ldots, N - M + 1\}\)</span>. The quantities <span class="math inline">\(p(y_{i&lt;M} \,|\, y_{&lt;i})\)</span> can be computed with the help of the posterior distribution <span class="math inline">\(p(\theta \,|\, y_{&lt;i})\)</span> of the parameters <span class="math inline">\(\theta\)</span> conditional on only the first <span class="math inline">\(i-1\)</span> observations of the time-series:</p>
<p><span class="math display">\[
p(y_{i&lt;M} \,| \, y_{&lt;i}) = 
  \int p(y_{i&lt;M} \,| \, y_{&lt;i}, \theta) \, p(\theta\,|\,y_{&lt;i}) \,d\theta. 
\]</span></p>
<p>Having obtained <span class="math inline">\(S\)</span> draws <span class="math inline">\((\theta_{&lt;i}^{(1)}, \ldots, \theta_{&lt;i}^{(S)})\)</span> from the posterior distribution <span class="math inline">\(p(\theta\,|\,y_{&lt;i})\)</span>, we can estimate <span class="math inline">\(p(y_{i&lt;M} | y_{&lt;i})\)</span> as</p>
<p><span class="math display">\[
p(y_{i&lt;M} \,|\, y_{&lt;i}) \approx \sum_{s=1}^S p(y_{i&lt;M} \,|\, y_{&lt;i}, \theta_{&lt;i}^{(s)}).
\]</span></p>
<p>In the following, we consider factorizable models in which the response values are conditionally independent given the parameters and the likelihood can be written in the familiar form</p>
<p><span class="math display">\[
p(\mathbf{y} \,|\, \theta) = \prod_{i=1}^N p(y_i \,|\, \theta).
\]</span></p>
<p>In this case, <span class="math inline">\(p(y_{i&lt;M} \,|\, y_{&lt;i}, \theta_{&lt;i})\)</span> reduces to <span class="math display">\[
p(y_{i&lt;M} \,|\, \theta_{&lt;i}) = \prod_{j = i}^{i + M -1} p(y_j \,|\, \theta_{&lt;i}),
\]</span> due to the assumption of conditional independence between <span class="math inline">\(y_{i&lt;M}\)</span> and <span class="math inline">\(y_{&lt;i}\)</span> given <span class="math inline">\(\theta_{&lt;i}\)</span>.</p>
<p>Non-factorizable models, which do not make this assumption, are discussed in a separate vignette <a href="http://mc-stan.org/loo/articles/loo2-non-factorizable.html"><em>Leave-one-out cross-validation for non-factorizable models</em></a>.</p>
</div>
<div id="approximate_MSAP" class="section level2">
<h2 class="hasAnchor">
<a href="#approximate_MSAP" class="anchor"></a>Approximate <span class="math inline">\(M\)</span>-SAP using importance-sampling</h2>
<p>Unfortunately, the math above makes use of the posterior distributions from many different fits of the model to different subsets of the data. That is, to obtain the predictive density <span class="math inline">\(p(y_{i&lt;M} \,|\, y_{&lt;i})\)</span> requires fitting a model to only the first <span class="math inline">\(i-1\)</span> data points, and we will need to do this for every value of <span class="math inline">\(i\)</span> under consideration (all <span class="math inline">\(i \in \{L + 1, \ldots, N - M + 1\}\)</span>).</p>
<p>To reduce the number of models that need to be fit for the purpose of obtaining each of the densities <span class="math inline">\(p(y_{i&lt;M} \,|\, y_{&lt;i})\)</span>, we propose the following algorithm. Starting with <span class="math inline">\(i = N - M + 1\)</span>, we approximate each <span class="math inline">\(p(y_{i&lt;M} \,|\, y_{&lt;i})\)</span> using Pareto smoothed importance sampling (PSIS, Vehtari et al, 2017ab):</p>
<p><span class="math display">\[
 p(y_{i&lt;M} \,|\, y_{&lt;i}) \approx
   \frac{ \sum_{s=1}^S w_i^{(s)}\, p(y_{i&lt;M} \,|\, \theta^{(s)})}{ \sum_{s=1}^S w_i^{(s)}},
\]</span></p>
<p>where <span class="math inline">\(w_i^{(s)}\)</span> are importance weights and <span class="math inline">\(\theta^{(s)}\)</span> are draws from the posterior distribution based on <em>all</em> observations. To obtain <span class="math inline">\(w_i^{(s)}\)</span>, we first compute the raw importance ratios</p>
<p><span class="math display">\[
r_i^{(s)} \propto \frac{1}{\prod_{j = i}^N p(y_j \,|\, \,\theta^{(s)})},
\]</span></p>
<p>and then stabilize them using PSIS.</p>
<p>We then <em>decrease</em> <span class="math inline">\(i\)</span> by <span class="math inline">\(1\)</span> (i.e., we move backwards in time) and repeat the process. At some observation <span class="math inline">\(i\)</span>, the variability of importance ratios <span class="math inline">\(r_i^{(s)}\)</span> will become too large and importance sampling fails. We will refer to this particular value of <span class="math inline">\(i\)</span> as <span class="math inline">\(i^\star_1\)</span>. To identify the value of <span class="math inline">\(i^\star_1\)</span> we check for which value of <span class="math inline">\(i\)</span> does the estimated shape parameter <span class="math inline">\(k\)</span> of the generalized Pareto distribution first crosses a certain threshold. Only then do we refit the model using only observations before <span class="math inline">\(i^\star_1\)</span> and then restart the process. In some cases we may only need to refit once and in other cases we will find a value <span class="math inline">\(i^\star_2\)</span> that requires a second refitting, maybe an <span class="math inline">\(i^\star_3\)</span> that requires a third refitting, and so on. We repeat the refitting as few times as is required (only if <span class="math inline">\(k &gt; \text{threshold}\)</span>) until we arrive at <span class="math inline">\(i = L+1\)</span>. Recall that <span class="math inline">\(L\)</span> is the minimum number of observations we have deemed acceptable for making predictions (setting <span class="math inline">\(L=0\)</span> means predictions of all observations should be computed).</p>
<p>For LOO, we recommend to use a threshold of <span class="math inline">\(0.7\)</span> (Vehtari et al, 2017ab), but for LFO, the threshold should be smaller as influential observations will affect all pointwise LFO approximations until the next refit and thus much stronger than in LOO. For the present case study, we choose a threshold of <span class="math inline">\(0.6\)</span>, but more experiments are needed to give general recommendations about the threshold in LFO.</p>
</div>
<div id="autoregressive-models" class="section level2">
<h2 class="hasAnchor">
<a href="#autoregressive-models" class="anchor"></a>Autoregressive models</h2>
<p>Autoregressive (AR) models are some of the most commonly used time-series models. An AR(p) model —an autoregressive model of order <span class="math inline">\(p\)</span>— can be defined as</p>
<p><span class="math display">\[
y_i = \eta_i + \sum_{k = 1}^p \varphi_k y_{i - k} + \varepsilon_i,
\]</span></p>
<p>where <span class="math inline">\(\eta_i\)</span> is the linear predictor for the <span class="math inline">\(i\)</span>th observation, <span class="math inline">\(\phi_k\)</span> are the autoregressive parameters and <span class="math inline">\(\varepsilon_i\)</span> are pairwise independent errors, which are usually assumed to be normally distributed with equal variance <span class="math inline">\(\sigma^2\)</span>. The model implies a recursive formula that allows for computing the right-hand side of the above equation for observation <span class="math inline">\(i\)</span> based on the values of the equations for previous observations.</p>
</div>
<div id="case-study-annual-measurements-of-the-level-of-lake-huron" class="section level2">
<h2 class="hasAnchor">
<a href="#case-study-annual-measurements-of-the-level-of-lake-huron" class="anchor"></a>Case Study: Annual measurements of the level of Lake Huron</h2>
<p>To illustrate the application of PSIS-LFO-CV for estimating expected <span class="math inline">\(M\)</span>-SAP performance, we will fit a model for 98 annual measurements of the water level (in feet) of <a href="https://en.wikipedia.org/wiki/Lake_Huron">Lake Huron</a> from the years 1875–1972. This data set is found in the <strong>datasets</strong> R package, which is installed automatically with <strong>R</strong>.</p>
<p>In addition to the <strong>loo</strong> package, for this analysis we will use the <strong>brms</strong> interface to Stan to generate a Stan program and fit the model, and also the <strong>bayesplot</strong> and <strong>ggplot2</strong> packages for plotting.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">"loo"</span>)
<span class="kw">library</span>(<span class="st">"brms"</span>)
<span class="kw">library</span>(<span class="st">"bayesplot"</span>)
<span class="kw">library</span>(<span class="st">"ggplot2"</span>)
<span class="kw">color_scheme_set</span>(<span class="st">"brightblue"</span>)
<span class="kw">theme_set</span>(<span class="kw">theme_default</span>())

CHAINS &lt;-<span class="st"> </span><span class="dv">4</span>
SEED &lt;-<span class="st"> </span><span class="dv">1234</span>
<span class="kw">set.seed</span>(SEED)</code></pre></div>
<p>Before fitting a model, we will first put the data into a data frame and then look at the time series.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">N &lt;-<span class="st"> </span><span class="kw">length</span>(LakeHuron)
df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">y =</span> <span class="kw">as.numeric</span>(LakeHuron),
  <span class="dt">year =</span> <span class="kw">as.numeric</span>(<span class="kw">time</span>(LakeHuron)),
  <span class="dt">time =</span> <span class="dv">1</span>:N
)

<span class="co"># save plot labels to reuse them</span>
plot_labs &lt;-<span class="st"> </span><span class="kw">labs</span>(
  <span class="dt">y =</span> <span class="st">"Water Level (ft)"</span>, 
  <span class="dt">x =</span> <span class="st">"Year"</span>,
  <span class="dt">title =</span> <span class="st">"Water Level in Lake Huron (1875-1972)"</span>
) 

<span class="kw">ggplot</span>(df, <span class="kw">aes</span>(<span class="dt">x =</span> year, <span class="dt">y =</span> y)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">1</span>) +
<span class="st">  </span>plot_labs</code></pre></div>
<p><img src="loo2-lfo_files/figure-html/unnamed-chunk-2-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>The above plot shows rather strong autocorrelation of the time-series as well as some trend towards lower levels for later points in time.</p>
<p>We can specify an AR(4) model for these data using the <strong>brms</strong> package as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">control &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">0.95</span>)
fit &lt;-<span class="st"> </span><span class="kw">brm</span>(
  y ~<span class="st"> </span><span class="dv">1</span>, 
  <span class="dt">data =</span> df, 
  <span class="dt">autocor =</span> <span class="kw">cor_ar</span>(~time, <span class="dt">p =</span> <span class="dv">4</span>), 
  <span class="dt">prior =</span> <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="fl">0.5</span>), <span class="dt">class =</span> <span class="st">"ar"</span>),
  <span class="dt">control =</span> control, 
  <span class="dt">seed =</span> SEED, 
  <span class="dt">chains =</span> CHAINS
)</code></pre></div>
<p>The model implied predictions along with the observed values can be plotted, which reveals a rather good fit to the data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">preds &lt;-<span class="st"> </span><span class="kw">posterior_predict</span>(fit)
preds &lt;-<span class="st"> </span><span class="kw">cbind</span>(
  <span class="dt">Estimate =</span> <span class="kw">colMeans</span>(preds), 
  <span class="dt">Q5 =</span> <span class="kw">apply</span>(preds, <span class="dv">2</span>, quantile, <span class="dt">probs =</span> <span class="fl">0.05</span>),
  <span class="dt">Q95 =</span> <span class="kw">apply</span>(preds, <span class="dv">2</span>, quantile, <span class="dt">probs =</span> <span class="fl">0.95</span>)
)

<span class="kw">ggplot</span>(<span class="kw">cbind</span>(df, preds), <span class="kw">aes</span>(<span class="dt">x =</span> year, <span class="dt">y =</span> Estimate)) +
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="kw">aes</span>(<span class="dt">ymin =</span> Q5, <span class="dt">ymax =</span> Q95), <span class="dt">stat =</span> <span class="st">"identity"</span>, <span class="dt">size =</span> <span class="fl">0.5</span>) +
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y =</span> y)) +<span class="st"> </span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">subtitle =</span> <span class="st">"Mean (blue) and 90% predictive intervals (gray) vs. observed data (black)"</span>) +
<span class="st">  </span>plot_labs</code></pre></div>
<p><img src="loo2-lfo_files/figure-html/unnamed-chunk-3-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>To allow for reasonable predictions of future values, we will require at least <span class="math inline">\(L = 20\)</span> historical observations (20 years) to make predictions.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">L &lt;-<span class="st"> </span><span class="dv">20</span></code></pre></div>
<p>We first perform approximate leave-one-out cross-validation (LOO-CV) for the purpose of later comparison with exact and approximate LFO-CV for the 1-SAP case.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">loo_cv &lt;-<span class="st"> </span><span class="kw"><a href="../reference/loo.html">loo</a></span>(<span class="kw">log_lik</span>(fit)[, (L +<span class="st"> </span><span class="dv">1</span>):N])
<span class="kw">print</span>(loo_cv)</code></pre></div>
<pre><code>
Computed from 4000 by 78 log-likelihood matrix

         Estimate   SE
elpd_loo    -89.0  6.5
p_loo         4.2  0.9
looic       178.0 12.9
------
Monte Carlo SE of elpd_loo is 0.0.

All Pareto k estimates are good (k &lt; 0.5).
See help('pareto-k-diagnostic') for details.</code></pre>
</div>
<div id="step-ahead-predictions-leaving-out-all-future-values" class="section level2">
<h2 class="hasAnchor">
<a href="#step-ahead-predictions-leaving-out-all-future-values" class="anchor"></a>1-step-ahead predictions leaving out all future values</h2>
<p>The most basic version of <span class="math inline">\(M\)</span>-SAP is 1-SAP, in which we predict only one step ahead. In this case, <span class="math inline">\(y_{i&lt;M}\)</span> simplifies to <span class="math inline">\(y_{i}\)</span> and the LFO-CV algorithm becomes considerably simpler than for larger values of <span class="math inline">\(M\)</span>.</p>
<div id="exact-1-step-ahead-predictions" class="section level3">
<h3 class="hasAnchor">
<a href="#exact-1-step-ahead-predictions" class="anchor"></a>Exact 1-step-ahead predictions</h3>
<p>Before we compute approximate LFO-CV using PSIS we will first compute exact LFO-CV for the 1-SAP case so we can use it as a benchmark later. The initial step for the exact computation is to calculate the log-predictive densities by refitting the model many times:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">loglik_exact &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">nrow =</span> <span class="kw">nsamples</span>(fit), <span class="dt">ncol =</span> N)
for (i in N:<span class="kw">max</span>(L +<span class="st"> </span><span class="dv">1</span>, <span class="dv">2</span>)) {
  fit_i &lt;-<span class="st"> </span><span class="kw">update</span>(fit, <span class="dt">newdata =</span> df[-(i:N), ], <span class="dt">recompile =</span> <span class="ot">FALSE</span>)
  loglik_exact[, i] &lt;-<span class="st"> </span><span class="kw">log_lik</span>(fit_i, <span class="dt">newdata =</span> df[<span class="dv">1</span>:i, ])[, i]
}</code></pre></div>
<p>Then we compute the exact expected log predictive density (ELPD):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># some helper functions we'll use throughout</span>

<span class="co"># more stable than log(sum(exp(x))) </span>
log_sum_exp &lt;-<span class="st"> </span>function(x) {
  max_x &lt;-<span class="st"> </span><span class="kw">max</span>(x)  
  max_x +<span class="st"> </span><span class="kw">log</span>(<span class="kw">sum</span>(<span class="kw">exp</span>(x -<span class="st"> </span>max_x)))
}

<span class="co"># more stable than log(mean(exp(x)))</span>
log_mean_exp &lt;-<span class="st"> </span>function(x) {
  <span class="kw">log_sum_exp</span>(x) -<span class="st"> </span><span class="kw">log</span>(<span class="kw">length</span>(x))
}

<span class="co"># compute log of raw importance ratios</span>
<span class="co"># sums over observations *not* over posterior samples</span>
sum_log_ratios &lt;-<span class="st"> </span>function(ll, <span class="dt">ids =</span> <span class="ot">NULL</span>) {
  if (!<span class="kw">is.null</span>(ids)) ll &lt;-<span class="st"> </span>ll[, ids, drop =<span class="st"> </span><span class="ot">FALSE</span>]
  -<span class="st"> </span><span class="kw">rowSums</span>(ll)
}

<span class="co"># for printing comparisons later</span>
rbind_print &lt;-<span class="st"> </span>function(...) {
  <span class="kw">round</span>(<span class="kw">rbind</span>(...), <span class="dt">digits =</span> <span class="dv">2</span>)
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">exact_elpds_1sap &lt;-<span class="st"> </span><span class="kw">apply</span>(loglik_exact, <span class="dv">2</span>, log_mean_exp)
exact_elpd_1sap &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dt">ELPD =</span> <span class="kw">sum</span>(exact_elpds_1sap[-(<span class="dv">1</span>:L)]))

<span class="kw">rbind_print</span>(
  <span class="st">"LOO"</span> =<span class="st"> </span>loo_cv$estimates[<span class="st">"elpd_loo"</span>, <span class="st">"Estimate"</span>],
  <span class="st">"LFO"</span> =<span class="st"> </span>exact_elpd_1sap
)</code></pre></div>
<pre><code>      ELPD
LOO -89.02
LFO -93.60</code></pre>
<p>We see that the ELPD from LFO-CV for 1-step-ahead predictions is lower than the ELPD estimate from LOO-CV, which should be expected since LOO-CV is making use of more of the time series. That is, since the LFO-CV approach only uses observations from before the left-out data point but LOO-CV uses <em>all</em> data points other than the left-out observation, we should expect to see the larger ELPD from LOO-CV.</p>
</div>
<div id="approximate-1-step-ahead-predictions" class="section level3">
<h3 class="hasAnchor">
<a href="#approximate-1-step-ahead-predictions" class="anchor"></a>Approximate 1-step-ahead predictions</h3>
<p>For illustrative purposes, we will first compute approximate 1-SAP without any refitting, even when the Pareto <span class="math inline">\(k\)</span> estimate is too large. This will of course be a poor approximation to exact 1-SAP, in particular if the Pareto <span class="math inline">\(k\)</span> estimates increase rather quickly beyond the threshold up to which PSIS tends to produce stable results (<span class="math inline">\(k &lt; 0.7\)</span>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">approx_elpds_1sap_no_refit &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, N)
loglik &lt;-<span class="st"> </span><span class="kw">log_lik</span>(fit)
ids &lt;-<span class="st"> </span>N:(L +<span class="st"> </span><span class="dv">1</span>)
ks &lt;-<span class="st"> </span><span class="ot">NULL</span>

for (i in ids) {
  logratio &lt;-<span class="st"> </span><span class="kw">sum_log_ratios</span>(loglik, i:N)
  psis_part &lt;-<span class="st"> </span><span class="kw">suppressWarnings</span>(<span class="kw"><a href="../reference/psis.html">psis</a></span>(logratio))
  ks &lt;-<span class="st"> </span><span class="kw">c</span>(ks, <span class="kw"><a href="../reference/pareto-k-diagnostic.html">pareto_k_values</a></span>(psis_part))
  lw_i &lt;-<span class="st"> </span><span class="kw">weights</span>(psis_part, <span class="dt">normalize =</span> <span class="ot">TRUE</span>)[, <span class="dv">1</span>]
  approx_elpds_1sap_no_refit[i] &lt;-<span class="st"> </span><span class="kw">log_sum_exp</span>(lw_i +<span class="st"> </span>loglik[, i])
}</code></pre></div>
<p>If we plot the Pareto <span class="math inline">\(k\)</span> estimates we can see that they do start to increase quickly and that once we work backwards to about halfway through the data points we get <span class="math inline">\(k &gt; 0.7\)</span>. This is indicated by the vertical line in the plot below, which corresponds to the point <span class="math inline">\(i^\star_1\)</span> discussed in Section <a href="#approximate_MSAP">Approximate <span class="math inline">\(M\)</span>-SAP using importance-sampling</a> above.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">plot_ks &lt;-<span class="st"> </span>function(ks, ids, <span class="dt">thres =</span> <span class="fl">0.7</span>) {
  dat_ks &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">ks =</span> ks, <span class="dt">ids =</span> ids)
  <span class="kw">ggplot</span>(dat_ks, <span class="kw">aes</span>(<span class="dt">x =</span> ids, <span class="dt">y =</span> ks)) +<span class="st"> </span>
<span class="st">    </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">color =</span> ks &gt;<span class="st"> </span>thres), <span class="dt">shape =</span> <span class="dv">3</span>, <span class="dt">show.legend =</span> <span class="ot">FALSE</span>) +<span class="st"> </span>
<span class="st">    </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> thres, <span class="dt">linetype =</span> <span class="dv">2</span>, <span class="dt">color =</span> <span class="st">"red2"</span>) +<span class="st"> </span>
<span class="st">    </span><span class="kw">scale_color_manual</span>(<span class="dt">values =</span> <span class="kw">c</span>(<span class="st">"cornflowerblue"</span>, <span class="st">"darkblue"</span>)) +<span class="st"> </span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">"Data point"</span>, <span class="dt">y =</span> <span class="st">"Pareto k"</span>) +<span class="st"> </span>
<span class="st">    </span><span class="kw">ylim</span>(-<span class="fl">0.5</span>, <span class="fl">1.5</span>)
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot_ks</span>(ks, ids)</code></pre></div>
<p><img src="loo2-lfo_files/figure-html/unnamed-chunk-8-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>Consequently, it is not surprising that the resulting approximate ELPD for 1-SAP is far away from the exact ELPD we computed above:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">approx_elpd_1sap_no_refit &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">c</span>(<span class="dt">ELPD =</span> <span class="kw">sum</span>(approx_elpds_1sap_no_refit, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>))
<span class="kw">rbind_print</span>(
  <span class="st">"approx LFO (no refit)"</span> =<span class="st"> </span>approx_elpd_1sap_no_refit,
  <span class="st">"exact LFO"</span> =<span class="st"> </span>exact_elpd_1sap
)</code></pre></div>
<pre><code>                        ELPD
approx LFO (no refit) -89.28
exact LFO             -93.60</code></pre>
<p>Next, we compute approximate 1-SAP with refit at observations where the Pareto <span class="math inline">\(k\)</span> estimate exceeds the threshold of <span class="math inline">\(0.6\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">k_thres &lt;-<span class="st"> </span><span class="fl">0.6</span></code></pre></div>
<p>The code becomes a little bit more involved to handle the refitting procedure. Note that we can compute exact 1-SAP at the refitting points, which comes with no additional computational costs since we had to refit the model anyway.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">loglik &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">nrow =</span> <span class="kw">nsamples</span>(fit), <span class="dt">ncol =</span> N)
approx_elpds_1sap &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, N)

fit_part &lt;-<span class="st"> </span>fit
ids &lt;-<span class="st"> </span>N:(L +<span class="st"> </span><span class="dv">1</span>)
i_refit &lt;-<span class="st"> </span>N
refits &lt;-<span class="st"> </span><span class="ot">NULL</span>
ks &lt;-<span class="st"> </span><span class="ot">NULL</span>

for (i in ids) {
  loglik[, i] &lt;-<span class="st"> </span><span class="kw">log_lik</span>(fit_part)[, i]
  logratio &lt;-<span class="st"> </span><span class="kw">sum_log_ratios</span>(loglik, i:i_refit)
  psis_part &lt;-<span class="st"> </span><span class="kw">suppressWarnings</span>(<span class="kw"><a href="../reference/psis.html">psis</a></span>(logratio))
  k &lt;-<span class="st"> </span><span class="kw"><a href="../reference/pareto-k-diagnostic.html">pareto_k_values</a></span>(psis_part)
  ks &lt;-<span class="st"> </span><span class="kw">c</span>(ks, k)
  if (k &gt;<span class="st"> </span>k_thres) {
    <span class="co"># refit the model based on the first i-1 observations</span>
    i_refit &lt;-<span class="st"> </span>i
    refits &lt;-<span class="st"> </span><span class="kw">c</span>(refits, i)
    fit_part &lt;-<span class="st"> </span><span class="kw">update</span>(fit_part, <span class="dt">newdata =</span> df[<span class="dv">1</span>:(i -<span class="st"> </span><span class="dv">1</span>), ], <span class="dt">recompile =</span> <span class="ot">FALSE</span>)
    loglik[, i] &lt;-<span class="st"> </span><span class="kw">log_lik</span>(fit_part, <span class="dt">newdata =</span> df[<span class="dv">1</span>:i, ])[, i]
    approx_elpds_1sap[i] &lt;-<span class="st"> </span><span class="kw">log_mean_exp</span>(loglik[, i])
  } else {
    lw_i &lt;-<span class="st"> </span><span class="kw">weights</span>(psis_part, <span class="dt">normalize =</span> <span class="ot">TRUE</span>)[, <span class="dv">1</span>]
    approx_elpds_1sap[i] &lt;-<span class="st"> </span><span class="kw">log_sum_exp</span>(lw_i +<span class="st"> </span>loglik[, i])
  }
} </code></pre></div>
<p>We see that the final Pareto-<span class="math inline">\(k\)</span>-estimates are mostly well below the threshold of 0.6 and that we only needed to refit the model 11 times at observations 82, 64, 58, 57, 56, 54, 47, 35, 23, 22, 21.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot_ks</span>(ks, ids)</code></pre></div>
<p><img src="loo2-lfo_files/figure-html/unnamed-chunk-11-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>The approximate 1-SAP ELPD is remarkably similar to the exact 1-SAP ELPD computed above, which indicates our algorithm to compute approximate 1-SAP worked well for the present data and model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">approx_elpd_1sap &lt;-<span class="st"> </span><span class="kw">sum</span>(approx_elpds_1sap, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)
<span class="kw">rbind_print</span>(
  <span class="st">"approx LFO (no refits)"</span> =<span class="st"> </span>approx_elpd_1sap_no_refit,
  <span class="st">"approx LFO (with refits)"</span> =<span class="st"> </span>approx_elpd_1sap,
  <span class="st">"exact LFO"</span> =<span class="st"> </span>exact_elpd_1sap
)</code></pre></div>
<pre><code>                           ELPD
approx LFO (no refits)   -89.28
approx LFO (with refits) -92.17
exact LFO                -93.60</code></pre>
<p>Plotting exact against approximate predictions, we see that no approximation value deviates far from its exact counterpart, providing further evidence for the good quality of our approximation.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dat_elpd &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">approx_elpd =</span> approx_elpds_1sap,
  <span class="dt">exact_elpd =</span> exact_elpds_1sap
)

<span class="kw">ggplot</span>(dat_elpd, <span class="kw">aes</span>(<span class="dt">x =</span> approx_elpd, <span class="dt">y =</span> exact_elpd)) +
<span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">color =</span> <span class="st">"gray30"</span>) +
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">2</span>) +
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">"Approximate ELPDs"</span>, <span class="dt">y =</span> <span class="st">"Exact ELPDs"</span>)</code></pre></div>
<p><img src="loo2-lfo_files/figure-html/unnamed-chunk-13-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>No observation shows a difference between the exact and approximate ELPD calculations of more than 0.77 and the average difference is 0.041, resulting in a close approximation.</p>
</div>
</div>
<div id="m-step-ahead-predictions-leaving-out-all-future-values" class="section level2">
<h2 class="hasAnchor">
<a href="#m-step-ahead-predictions-leaving-out-all-future-values" class="anchor"></a><span class="math inline">\(M\)</span>-step-ahead predictions leaving out all future values</h2>
<p>To illustrate the application of <span class="math inline">\(M\)</span>-SAP for <span class="math inline">\(M &gt; 1\)</span>, we compute next exact and approximate LFO-CV for the 4-SAP case.</p>
<div id="exact-m-step-ahead-predictions" class="section level3">
<h3 class="hasAnchor">
<a href="#exact-m-step-ahead-predictions" class="anchor"></a>Exact <span class="math inline">\(M\)</span>-step-ahead predictions</h3>
<p>The necessary steps are the same as for 1-SAP with the exception that the log-density values of interest are now the sums of the log predictive densities of four consequtive observations. Further, the stability of the PSIS approximation actually stays the same for all <span class="math inline">\(M\)</span> as it only depends on the number of observations we leave out, not on the number of observations we predict.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">M &lt;-<span class="st"> </span><span class="dv">4</span>
loglikm &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">nrow =</span> <span class="kw">nsamples</span>(fit), <span class="dt">ncol =</span> N)
for (i in (N -<span class="st"> </span>M +<span class="st"> </span><span class="dv">1</span>):<span class="kw">max</span>(L +<span class="st"> </span><span class="dv">1</span>, <span class="dv">2</span>)) {
  fit_i &lt;-<span class="st"> </span><span class="kw">update</span>(fit, <span class="dt">newdata =</span> df[-(i:N), ], <span class="dt">recompile =</span> <span class="ot">FALSE</span>)
  ll &lt;-<span class="st"> </span><span class="kw">log_lik</span>(fit_i, <span class="dt">newdata =</span> df[<span class="dv">1</span>:(i +<span class="st"> </span>M -<span class="st"> </span><span class="dv">1</span>), ])
  loglikm[, i] &lt;-<span class="st"> </span><span class="kw">rowSums</span>(ll[, i:(i +<span class="st"> </span>M -<span class="st"> </span><span class="dv">1</span>)])
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">exact_elpds_4sap &lt;-<span class="st"> </span><span class="kw">apply</span>(loglikm, <span class="dv">2</span>, log_mean_exp)
(exact_elpd_4sap &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dt">ELPD =</span> <span class="kw">sum</span>(exact_elpds_4sap, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)))</code></pre></div>
<pre><code>     ELPD 
-355.8638 </code></pre>
</div>
<div id="approximate-m-step-ahead-predictions" class="section level3">
<h3 class="hasAnchor">
<a href="#approximate-m-step-ahead-predictions" class="anchor"></a>Approximate <span class="math inline">\(M\)</span>-step-ahead predictions</h3>
<p>Computing the approximate PSIS-LFO-CV for the 4-SAP case is a little bit more involved than the approximate version for the 1-SAP case, although the underlying principles remain the same.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">loglikm &lt;-<span class="st"> </span>loglik &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">nrow =</span> <span class="kw">nsamples</span>(fit), <span class="dt">ncol =</span> N)
approx_elpds_4sap &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, N)
fit_part &lt;-<span class="st"> </span>fit
ids &lt;-<span class="st"> </span>(N -<span class="st"> </span>M +<span class="st"> </span><span class="dv">1</span>):(L +<span class="st"> </span><span class="dv">1</span>)
i_refit &lt;-<span class="st"> </span>N -<span class="st"> </span>M +<span class="st"> </span><span class="dv">1</span>
refits &lt;-<span class="st"> </span><span class="ot">NULL</span>
ks &lt;-<span class="st"> </span><span class="ot">NULL</span>

loglik[, (N -<span class="st"> </span>M +<span class="st"> </span><span class="dv">2</span>):N] &lt;-<span class="st"> </span><span class="kw">log_lik</span>(fit_part)[, (N -<span class="st"> </span>M +<span class="st"> </span><span class="dv">2</span>):N]

for (i in ids) {
  ll &lt;-<span class="st"> </span><span class="kw">log_lik</span>(fit_part, <span class="dt">newdata =</span> df[<span class="dv">1</span>:(i +<span class="st"> </span>M -<span class="st"> </span><span class="dv">1</span>), ])
  loglikm[, i] &lt;-<span class="st"> </span><span class="kw">rowSums</span>(ll[, i:(i +<span class="st"> </span>M -<span class="st"> </span><span class="dv">1</span>)])
  loglik[, i] &lt;-<span class="st"> </span>ll[, i]
  logratio &lt;-<span class="st"> </span><span class="kw">sum_log_ratios</span>(loglik, i:i_refit)
  psis_part &lt;-<span class="st"> </span><span class="kw">suppressWarnings</span>(<span class="kw"><a href="../reference/psis.html">psis</a></span>(logratio))
  k &lt;-<span class="st"> </span><span class="kw"><a href="../reference/pareto-k-diagnostic.html">pareto_k_values</a></span>(psis_part)
  ks &lt;-<span class="st"> </span><span class="kw">c</span>(ks, k)
  if (k &gt;<span class="st"> </span>k_thres) {
    <span class="co"># refit the model based on the first i-1 observations</span>
    i_refit &lt;-<span class="st"> </span>i
    refits &lt;-<span class="st"> </span><span class="kw">c</span>(refits, i)
    fit_part &lt;-<span class="st"> </span><span class="kw">update</span>(
      fit_part, <span class="dt">newdata =</span> df[<span class="dv">1</span>:(i -<span class="st"> </span><span class="dv">1</span>), ], 
      <span class="dt">recompile =</span> <span class="ot">FALSE</span>
    )
    ll &lt;-<span class="st"> </span><span class="kw">log_lik</span>(fit_part, <span class="dt">newdata =</span> df[<span class="dv">1</span>:(i +<span class="st"> </span>M -<span class="st"> </span><span class="dv">1</span>), ])
    loglik[, i] &lt;-<span class="st"> </span>ll[, i]
    loglikm[, i] &lt;-<span class="st"> </span><span class="kw">rowSums</span>(ll[, i:(i +<span class="st"> </span>M -<span class="st"> </span><span class="dv">1</span>)])
    approx_elpds_4sap[i] &lt;-<span class="st"> </span><span class="kw">log_mean_exp</span>(loglikm[, i])
  } else {
    lw_i &lt;-<span class="st"> </span><span class="kw">weights</span>(psis_part, <span class="dt">normalize =</span> <span class="ot">TRUE</span>)[, <span class="dv">1</span>]
    approx_elpds_4sap[i] &lt;-<span class="st"> </span><span class="kw">log_sum_exp</span>(lw_i +<span class="st"> </span>loglikm[, i])
  }
} </code></pre></div>
<p>Again, we see that the final Pareto-<span class="math inline">\(k\)</span>-estimates are mostly well below the threshold and that we only needed to refit the model 11 times at observations 82, 57, 56, 54, 53, 49, 36, 24, 23, 22, 21.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot_ks</span>(ks, ids)</code></pre></div>
<p><img src="loo2-lfo_files/figure-html/unnamed-chunk-16-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>The approximate ELPD computed for the 4-SAP case is not as close to its exact counterpart as in the 1-SAP case. Likely, we need to lower the threshold for the Pareto-k-values from 0.6 to 0.55 or even 0.5 in order to achieve better results.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">approx_elpd_4sap &lt;-<span class="st"> </span><span class="kw">sum</span>(approx_elpds_4sap, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)
<span class="kw">rbind_print</span>(
  <span class="st">"Approx LFO"</span> =<span class="st"> </span>approx_elpd_4sap,
  <span class="st">"Exact LFO"</span> =<span class="st"> </span>exact_elpd_4sap
)</code></pre></div>
<pre><code>              ELPD
Approx LFO -358.04
Exact LFO  -355.86</code></pre>
<p>Plotting exact against approximate pointwise predictions confirms that, for a few specific data points, the approximate predictions underestimate the exact predictions.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dat_elpd_4sap &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">approx_elpd =</span> approx_elpds_4sap,
  <span class="dt">exact_elpd =</span> exact_elpds_4sap
)

<span class="kw">ggplot</span>(dat_elpd_4sap, <span class="kw">aes</span>(<span class="dt">x =</span> approx_elpd, <span class="dt">y =</span> exact_elpd)) +
<span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">color =</span> <span class="st">"gray30"</span>) +
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">2</span>) +
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">"Approximate ELPDs"</span>, <span class="dt">y =</span> <span class="st">"Exact ELPDs"</span>)</code></pre></div>
<p><img src="loo2-lfo_files/figure-html/unnamed-chunk-18-1.png" width="60%" style="display: block; margin: auto;"></p>
</div>
</div>
<div id="step-ahead-predictions-leaving-out-blocks-of-future-values" class="section level2">
<h2 class="hasAnchor">
<a href="#step-ahead-predictions-leaving-out-blocks-of-future-values" class="anchor"></a>1-step-ahead predictions leaving out blocks of future values</h2>
<p>Depending on the particular time-series model and data, the Pareto <span class="math inline">\(k\)</span> estimates may exceed 0.6 rather quickly (i.e., after only few observations) and so many refits may be required even when carrying out the PSIS approximation to LFO-CV. In this case, another option is to exclude only the block of <span class="math inline">\(B\)</span> future values that directly follow the observations to be predicted while retaining all of the more distant values <span class="math inline">\(y_{i&gt;B} = (y_{i + B}, \ldots, y_N)\)</span>. This will usually result in lower Pareto <span class="math inline">\(k\)</span> estimates and thus less refitting.</p>
<p>This block-<span class="math inline">\(M\)</span>-SAP version closely resembles the basic <span class="math inline">\(M\)</span>-SAP only if values in the distant future, <span class="math inline">\(y_{&gt;B}\)</span>, contain little information about the current observations being predicted. Whether this assumption is justified will depend on the data and model.</p>
<p>We will demonstrate the LFO-CV approach for the block-<span class="math inline">\(M\)</span>-SAP case using block-1-SAP.</p>
<div id="exact-lfo-cv-for-block-1-sap" class="section level3">
<h3 class="hasAnchor">
<a href="#exact-lfo-cv-for-block-1-sap" class="anchor"></a>Exact LFO-CV for block-1-SAP</h3>
<p>The differences between the code for LFO-CV for 1-SAP and the code for block-1-SAP are very small. We now just need to define a block size <span class="math inline">\(B\)</span> of left-out observations, which we set to <span class="math inline">\(B = 10\)</span> for the present case study.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">B &lt;-<span class="st"> </span><span class="dv">10</span>
loglik &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">nrow =</span> <span class="kw">nsamples</span>(fit), <span class="dt">ncol =</span> N)
for (i in N:(L +<span class="st"> </span><span class="dv">1</span>)) {
  to &lt;-<span class="st"> </span><span class="kw">min</span>(i +<span class="st"> </span>B -<span class="st"> </span><span class="dv">1</span>, N)
  fit_i &lt;-<span class="st"> </span><span class="kw">update</span>(fit, <span class="dt">newdata =</span> df[-(i:to), ], <span class="dt">recompile =</span> <span class="ot">FALSE</span>)
  loglik[, i] &lt;-<span class="st"> </span><span class="kw">log_lik</span>(fit_i, <span class="dt">newdata =</span> df[<span class="dv">1</span>:i, ])[, i]
}</code></pre></div>
<p>Comparing the exact block-1-SAP to the exact 1-SAP reveals no substantial difference for this particular data set and model, but this may very well be different for other data sets and models.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">exact_elpds_1sap_block &lt;-<span class="st"> </span><span class="kw">apply</span>(loglik, <span class="dv">2</span>, log_mean_exp)
exact_elpd_1sap_block &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dt">ELPD =</span> <span class="kw">sum</span>(exact_elpds_1sap_block, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>))
<span class="kw">rbind_print</span>(
  <span class="st">"Exact LFO-CV (1-SAP)"</span> =<span class="st"> </span>exact_elpd_1sap, 
  <span class="st">"Exact LFO-CV (block-1-SAP)"</span> =<span class="st"> </span>exact_elpd_1sap_block 
)</code></pre></div>
<pre><code>                             ELPD
Exact LFO-CV (1-SAP)       -93.60
Exact LFO-CV (block-1-SAP) -88.67</code></pre>
<p>If exact block-1-SAP and exact 1-SAP were different, it would not necessarily imply that observations depend on distant future values, but could instead be due to the fact that the model parameters were estimated more precisely in the case of block-1-SAP since more data are available, in particular for predicting observations early in the time series. If this is the case we would expect the differences between the pointwise ELPDs for the two cases to be larger for earlier observations. To some degree, this is also what we see when plotting the differences for the present example, although these differences happen to cancel each other out in this case:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dat_elpd_diff &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">elpd_diff =</span> exact_elpds_1sap_block -<span class="st"> </span>exact_elpds_1sap,
  <span class="dt">i =</span> <span class="kw">seq_along</span>(exact_elpds_1sap_block)
)

<span class="kw">ggplot</span>(dat_elpd_diff[(L +<span class="st"> </span><span class="dv">1</span>):N, ], <span class="kw">aes</span>(<span class="dt">x =</span> i, <span class="dt">y =</span> elpd_diff)) +
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">2</span>) +
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">"Data Point"</span>, <span class="dt">y =</span> <span class="st">"ELPD diff"</span>)</code></pre></div>
<p><img src="loo2-lfo_files/figure-html/unnamed-chunk-20-1.png" width="60%" style="display: block; margin: auto;"></p>
</div>
<div id="approximate-1-step-ahead-predictions-1" class="section level3">
<h3 class="hasAnchor">
<a href="#approximate-1-step-ahead-predictions-1" class="anchor"></a>Approximate 1-step-ahead predictions</h3>
<p>We compute approximate PSIS-LFO-CV for block-1-SAP as follows.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">loglik &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">nrow =</span> <span class="kw">nsamples</span>(fit), <span class="dt">ncol =</span> N)
approx_elpds_1sap_block &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, N)
fit_part &lt;-<span class="st"> </span>fit
ids &lt;-<span class="st"> </span>N:(L +<span class="st"> </span><span class="dv">1</span>)
i_refit &lt;-<span class="st"> </span>N
refits &lt;-<span class="st"> </span><span class="ot">NULL</span>
ks &lt;-<span class="st"> </span><span class="ot">NULL</span> 

for (i in ids) {
  loglik[, i] &lt;-<span class="st"> </span><span class="kw">log_lik</span>(fit_part)[, i]
  to &lt;-<span class="st"> </span><span class="kw">min</span>(i +<span class="st"> </span>B -<span class="st"> </span><span class="dv">1</span>, i_refit)
  logratio &lt;-<span class="st"> </span><span class="kw">sum_log_ratios</span>(loglik, i:to)
  psis_part &lt;-<span class="st"> </span><span class="kw">suppressWarnings</span>(<span class="kw"><a href="../reference/psis.html">psis</a></span>(logratio))
  k &lt;-<span class="st"> </span><span class="kw"><a href="../reference/pareto-k-diagnostic.html">pareto_k_values</a></span>(psis_part)
  ks &lt;-<span class="st"> </span><span class="kw">c</span>(ks, k)
  if (k &gt;<span class="st"> </span>k_thres) {
    <span class="co"># refit the model without a block of B observations</span>
    i_refit &lt;-<span class="st"> </span>i 
    refits &lt;-<span class="st"> </span><span class="kw">c</span>(refits, i)
    fit_part &lt;-<span class="st"> </span><span class="kw">update</span>(fit_part, <span class="dt">newdata =</span> df[-(i:to), ], <span class="dt">recompile =</span> <span class="ot">FALSE</span>)
    loglik[, i] &lt;-<span class="st"> </span><span class="kw">log_lik</span>(fit_part, <span class="dt">newdata =</span> df[<span class="dv">1</span>:i, ])[, i]
    approx_elpds_1sap_block[i] &lt;-<span class="st"> </span><span class="kw">log_mean_exp</span>(loglik[, i])
  } else {
    lw_i &lt;-<span class="st"> </span><span class="kw">weights</span>(psis_part, <span class="dt">normalize =</span> <span class="ot">TRUE</span>)[, <span class="dv">1</span>]
    approx_elpds_1sap_block[i] &lt;-<span class="st"> </span><span class="kw">log_sum_exp</span>(lw_i +<span class="st"> </span>loglik[, i])
  }
}</code></pre></div>
<p>Here we needed 1 refit(s), which is remarkable given that we have a time-series of 98 observations and are predicting for 98 - L = 78 of them.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot_ks</span>(ks, ids)</code></pre></div>
<p><img src="loo2-lfo_files/figure-html/unnamed-chunk-21-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>Consequently, it is not surprising that PSIS-LFO-CV for block-1-SAP matches the exact version closely.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">approx_elpd_1sap_block &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dt">ELPD =</span> <span class="kw">sum</span>(approx_elpds_1sap_block, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>))
<span class="kw">rbind_print</span>(
  <span class="st">"Exact LFO-CV (block-1-SAP)"</span> =<span class="st"> </span>exact_elpd_1sap_block,
  <span class="st">"Approx LFO-CV (block-1-SAP)"</span> =<span class="st"> </span>approx_elpd_1sap_block
)</code></pre></div>
<pre><code>                              ELPD
Exact LFO-CV (block-1-SAP)  -88.67
Approx LFO-CV (block-1-SAP) -88.10</code></pre>
<p>This is also visible in the plot of approximate against exact predictions.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dat_elpd_block &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">approx_elpd =</span> approx_elpds_1sap_block,
  <span class="dt">exact_elpd =</span> exact_elpds_1sap_block
)

<span class="kw">ggplot</span>(dat_elpd_block, <span class="kw">aes</span>(<span class="dt">x =</span> approx_elpd, <span class="dt">y =</span> exact_elpd)) +
<span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">color =</span> <span class="st">"gray30"</span>) +
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">2</span>) +
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">"Approximate ELPDs"</span>, <span class="dt">y =</span> <span class="st">"Exact ELPDs"</span>)</code></pre></div>
<p><img src="loo2-lfo_files/figure-html/unnamed-chunk-23-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>When increasing <span class="math inline">\(M\)</span> in block-M-SAP, we have to make sure to simultaneously increase the block size <span class="math inline">\(B\)</span>, as well, in order to keep the assumptions of block-M-SAP satisfied. This also implies that the stability of the PSIS approximation will decrease as we increase <span class="math inline">\(M\)</span> in block-M-SAP because we have to leave out more observations.</p>
</div>
</div>
<div id="conclusion" class="section level2">
<h2 class="hasAnchor">
<a href="#conclusion" class="anchor"></a>Conclusion</h2>
<p>In this case study we have shown how to do carry out exact and approximate leave-future-out cross-validation for <span class="math inline">\(M\)</span>-step-ahead prediction tasks. For the data and model used in our example the PSIS-LFO-CV algorithm provides reasonably stable and accurate results depite not requiring us to refit the model nearly as many times. For many other examples we expect similar performance, but the results will always vary from case to case depending on the particulars of the data and the time series model.</p>
<p><br></p>
</div>
<div id="references" class="section level2">
<h2 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h2>
<p>Vehtari A., Gelman A., &amp; Gabry J. (2017a). Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC. <em>Statistics and Computing</em>, 27(5), 1413–1432. <a href="doi:10.1007/s11222-016-9696-4" class="uri">doi:10.1007/s11222-016-9696-4</a>. <a href="http://link.springer.com/article/10.1007/s11222-016-9696-4">Online</a>. <a href="https://arxiv.org/abs/1507.04544">arXiv preprint arXiv:1507.04544</a>.</p>
<p>Vehtari A., Gelman A., &amp; Gabry J. (2017b). Pareto smoothed importance sampling. <a href="https://arxiv.org/abs/1507.02646">arXiv preprint arXiv:1507.02646</a>.</p>
<p><br></p>
</div>
<div id="appendix" class="section level2">
<h2 class="hasAnchor">
<a href="#appendix" class="anchor"></a>Appendix</h2>
<div id="appendix-session-information" class="section level3">
<h3 class="hasAnchor">
<a href="#appendix-session-information" class="anchor"></a>Appendix: Session information</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sessionInfo</span>()</code></pre></div>
<pre><code>R version 3.5.0 (2018-04-23)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 16299)

Matrix products: default

locale:
[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252   
[3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C                   
[5] LC_TIME=German_Germany.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] bayesplot_1.6.0 brms_2.5.2      ggplot2_3.0.0   Rcpp_0.12.19   
[5] loo_2.0.0       knitr_1.20     

loaded via a namespace (and not attached):
 [1] Brobdingnag_1.2-5    gtools_3.8.1         StanHeaders_2.17.2  
 [4] threejs_0.3.1        shiny_1.1.0          assertthat_0.2.0    
 [7] stats4_3.5.0         yaml_2.2.0           pillar_1.3.0        
[10] backports_1.1.2      lattice_0.20-35      glue_1.2.0          
[13] digest_0.6.18        promises_1.0.1       colorspace_1.3-2    
[16] htmltools_0.3.6      httpuv_1.4.4.2       Matrix_1.2-14       
[19] plyr_1.8.4           dygraphs_1.1.1.6     pkgconfig_2.0.1     
[22] rstan_2.17.4         purrr_0.2.5          xtable_1.8-2        
[25] mvtnorm_1.0-8        scales_0.5.0         later_0.7.3         
[28] tibble_1.4.2         DT_0.4               shinyjs_1.0         
[31] withr_2.1.2          lazyeval_0.2.1       magrittr_1.5        
[34] crayon_1.3.4         mime_0.5             memoise_1.1.0       
[37] evaluate_0.12        fs_1.2.6             nlme_3.1-137        
[40] MASS_7.3-50          xts_0.11-0           xml2_1.2.0          
[43] colourpicker_1.0     rsconnect_0.8.8      tools_3.5.0         
[46] matrixStats_0.54.0   stringr_1.3.1        munsell_0.5.0       
[49] bindrcpp_0.2.2       compiler_3.5.0       pkgdown_1.1.0.9000  
[52] rlang_0.2.2          grid_3.5.0           ggridges_0.5.0      
[55] rstudioapi_0.8       htmlwidgets_1.2      crosstalk_1.0.0     
[58] igraph_1.2.1         miniUI_0.1.1.1       labeling_0.3        
[61] base64enc_0.1-3      rmarkdown_1.10       codetools_0.2-15    
[64] gtable_0.2.0         inline_0.3.15        abind_1.4-5         
[67] roxygen2_6.1.0       reshape2_1.4.3       markdown_0.8        
[70] R6_2.3.0             gridExtra_2.3        rstantools_1.5.1    
[73] zoo_1.8-3            bridgesampling_0.5-2 dplyr_0.7.6         
[76] shinythemes_1.1.1    bindr_0.1.1          shinystan_2.5.0     
[79] commonmark_1.6       rprojroot_1.3-2      desc_1.2.0          
[82] stringi_1.2.3        parallel_3.5.0       tidyselect_0.2.4    
[85] coda_0.19-1         </code></pre>
</div>
<div id="appendix-licenses" class="section level3">
<h3 class="hasAnchor">
<a href="#appendix-licenses" class="anchor"></a>Appendix: Licenses</h3>
<ul>
<li>Code © 2018, Paul Bürkner, Aki Vehtari, Jonah Gabry (licensed under BSD-3).</li>
<li>Text © 2018, Paul Bürkner, Aki Vehtari, Jonah Gabry (licensed under CC-BY-NC 4.0).</li>
</ul>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#introduction">Introduction</a></li>
      <li><a href="#m-step-ahead-predictions"><span class="math inline">\(M\)</span>-step-ahead predictions</a></li>
      <li><a href="#approximate_MSAP">Approximate <span class="math inline">\(M\)</span>-SAP using importance-sampling</a></li>
      <li><a href="#autoregressive-models">Autoregressive models</a></li>
      <li><a href="#case-study-annual-measurements-of-the-level-of-lake-huron">Case Study: Annual measurements of the level of Lake Huron</a></li>
      <li><a href="#step-ahead-predictions-leaving-out-all-future-values">1-step-ahead predictions leaving out all future values</a></li>
      <li><a href="#m-step-ahead-predictions-leaving-out-all-future-values"><span class="math inline">\(M\)</span>-step-ahead predictions leaving out all future values</a></li>
      <li><a href="#step-ahead-predictions-leaving-out-blocks-of-future-values">1-step-ahead predictions leaving out blocks of future values</a></li>
      <li><a href="#conclusion">Conclusion</a></li>
      <li><a href="#references">References</a></li>
      <li><a href="#appendix">Appendix</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Aki Vehtari, Andrew Gelman, Jonah Gabry, Yuling Yao.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  

  </body>
</html>
