% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/loo_subsample.R
\name{loo_subsample}
\alias{loo_subsample}
\alias{loo_subsample.function}
\title{Efficient approximate leave-one-out cross-validation (LOO) using subsampling}
\usage{
loo_subsample(x, ...)

\method{loo_subsample}{function}(x, ..., data = NULL, draws = NULL,
  observations = 400, log_p = NULL, log_g = NULL, r_eff = NULL,
  save_psis = FALSE, cores = getOption("mc.cores", 1),
  loo_approximation = "plpd", loo_approximation_draws = NULL,
  estimator = "diff_srs", llgrad = NULL, llhess = NULL)
}
\arguments{
\item{x}{A function. The \strong{Methods (by class)}
section, below, has detailed descriptions of how to specify the inputs for
each method.}

\item{data, draws, ...}{For the \code{loo_subsample.function()} method and the \code{loo_i()}
function, these are the data, posterior draws, and other arguments to pass
to the log-likelihood function.}

\item{observations}{The subsample observations to use. The argument can take four (4) types of arguments.
If \code{NULL} is supplied, all observations are used and the algorithm just use standard loo or
loo_approximate_posterior.
If a single integer is supplied this is the number of observations that are subsampled.
If a vector of integers, this will be the indecies used to subset the data.
Note, these observations need to be subsampled with the same scheme as given by
\code{estimator}.
If a \code{psis_loo_ss} object is supplied, the same observations are used.}

\item{log_p}{Should be supplied if approximate posterior draws are used.
Default (\code{NULL}) posterior draws from true posterior (i.e. using MCMC).
The log-posterior (target) evaluated at S samples from the proposal
distribution (g). A vector of the same length as the number of posterior draws.}

\item{save_psis}{Should the \code{"psis"} object created internally by \code{loo_approximate_posterior()} be
saved in the returned object? See \link{loo} for details.}

\item{cores}{The number of cores to use for parallelization. This defaults to
the option \code{mc.cores} which can be set for an entire R session by
\code{options(mc.cores = NUMBER)}. The old option \code{loo.cores} is now
deprecated but will be given precedence over \code{mc.cores} until
\code{loo.cores} is removed in a future release. \strong{As of version
2.0.0 the default is now 1 core if \code{mc.cores} is not set}, but we
recommend using as many (or close to as many) cores as possible.
\itemize{
\item Note for Windows 10 users: it is \strong{strongly}
\href{https://github.com/stan-dev/loo/issues/94}{recommended} to avoid using
the \code{.Rprofile} file to set \code{mc.cores} (using the \code{cores} argument or
setting \code{mc.cores} interactively or in a script is fine).
}}

\item{loo_approximation}{What type of approximation of the loo_i:s should be used.
Default is \code{plpd} or log predictive density using the posterior expectation.
There are six different methods implemented to approximate loo_i:s.
See the references for more details.
\describe{
\item{\code{plpd}}{
uses the lpd based on point estimates (ie. \eqn{p(y_i|\hat{\theta})})}
\item{\code{lpd}}{
uses the lpds (ie. \eqn{p(y_i|y)})}
\item{\code{tis}}{
uses truncated importance sampling to approximate PSIS-LOO}
\item{\code{waic}}{
uses waic (ie. \eqn{p(y_i|y) - p_{waic}})}
\item{\code{waic_grad_marginal}}{
uses waic approximation using first order delta method and
posterior marginal variances to approximate \eqn{p_{waic}}
(ie. \eqn{p(y_i|\hat{\theta})}-p_waic_grad_marginal).
Require gradient of likelihood function.}
\item{\code{waic_grad}}{
uses waic approximation using first order delta method and
posterior covariance to approximate \eqn{p_{waic}}
(ie. \eqn{p(y_i|\hat{\theta})}-p_waic_grad).
Require gradient of likelihood function.}
\item{\code{waic_grad}}{
uses waic approximation using second order delta method and
posterior covariance to approximate \eqn{p_{waic}}
(ie. \eqn{p(y_i|\hat{\theta})}-p_waic_grad).
Require gradient and Hessian of likelihood function.}
}
As points estimates of \eqn{\hat{\theta}}, the expectation
of the posterior parameters  ares used.}

\item{loo_approximation_draws}{The number of posterior draws
used when integrating over the posterior.
Used by loo_approximation \code{lpd} and \code{waic}.}

\item{estimator}{How should elpd_loo, p_loo and looic be estimated.
Default is \code{diff_srs}.
\describe{
\item{\code{diff_srs}}{
uses the difference estimator with simple random sampling (srs).
p_loo is estimated using standard srs.}
\item{\code{hh}}{
uses the Hansen-Hurwitz estimator with sampling proportional
to size, where abs of loo_approximation is used as size.}
\item{\code{srs}}{
uses simple random sampling and ordinary estimation.}
}}

\item{llgrad}{the gradient of the log-likelihood. This is only used
with \code{waic_grad}, \code{waic_grad_marginal} and \code{waic_hess}.
Default is \code{NULL}.}

\item{llhess}{the hessian of the log-likelihood. This is only used
with \code{waic_hess}.
Default is \code{NULL}.}

\item{log_q}{Should be supplied if approximate posterior draws are used.
Default (\code{NULL}) posterior draws from true posterior (i.e. using MCMC).
The log-density (proposal) evaluated at S samples from the proposal
distribution (g). A vector of the same length as the number of posterior draws.}

\item{cores}{The number of cores to use for parallelization. This defaults to
the option \code{mc.cores} which can be set for an entire R session by
\code{options(mc.cores = NUMBER)}. The old option \code{loo.cores} is now
deprecated but will be given precedence over \code{mc.cores} until
\code{loo.cores} is removed in a future release. \strong{As of version
2.0.0 the default is now 1 core if \code{mc.cores} is not set}, but we
recommend using as many (or close to as many) cores as possible.
\itemize{
\item Note for Windows 10 users: it is \strong{strongly}
\href{https://github.com/stan-dev/loo/issues/94}{recommended} to avoid using
the \code{.Rprofile} file to set \code{mc.cores} (using the \code{cores} argument or
setting \code{mc.cores} interactively or in a script is fine).
}}
}
\value{
The \code{loo_subsample()} methods return a named list with class
\code{c("psis_loo_ap", "psis_loo", "loo")} with the additional slot:
\describe{
\item{\code{posterior_approximation}}{
A list with two vectors, \code{log_p} and \code{log_g} of the same length
containing the posterior density and the approximation density
for the individual dras.
}
}
}
\description{
Efficient approximate leave-one-out cross-validation (LOO) using subsampling
}
\details{
The \code{loo_subsample()} function is an S3 generic and methods are provided for
log-likelihood functions. The implementation work for both MCMC and for posterior
approximations where it is possible to compute the log density for the approximation.
}
\section{Methods (by class)}{
\itemize{
\item \code{function}: A function \code{f()} that takes arguments \code{data_i} and \code{draws} and returns a
vector containing the log-likelihood for a single observation \code{i} evaluated
at each posterior draw. The function should be written such that, for each
observation \code{i} in \code{1:N}, evaluating\preformatted{f(data_i = data[i,, drop=FALSE], draws = draws)
}

results in a vector of length \code{S} (size of posterior sample). The
log-likelihood function can also have additional arguments but \code{data_i} and
\code{draws} are required.

If using the function method then the arguments \code{data} and \code{draws} must also
be specified in the call to \code{loo()}:
\itemize{
\item \code{data}: A data frame or matrix containing the data (e.g.
observed outcome and predictors) needed to compute the pointwise
log-likelihood. For each observation \code{i}, the \code{i}th row of
\code{data} will be passed to the \code{data_i} argument of the
log-likelihood function.
\item \code{draws}: An object containing the posterior draws for any
parameters needed to compute the pointwise log-likelihood. Unlike
\code{data}, which is indexed by observation, for each observation the
entire object \code{draws} will be passed to the \code{draws} argument of
the log-likelihood function.
\item The \code{...} can be used if your log-likelihood function takes additional
arguments. These arguments are used like the \code{draws} argument in that they
are recycled for each observation.
}
}}

\references{
Magnusson, M., Riis Andersen, M., Jonasson, J. and Vehtari, A. (2019).
Leave-One-Out Cross-Validation for Large Data.
In \emph{International Conference on Machine Learning}

Magnusson, M., Riis Andersen, M., Jonasson, J. and Vehtari, A. (2019).
Leave-One-Out Cross-Validation for Model Comparison in Large Data.
}
\seealso{
loo, psis, loo_compare
}
