<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Model averaging/weighting via stacking or pseudo-BMA weighting — loo_model_weights • loo</title>

<!-- favicons -->
<link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png" />
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png" />
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png" />
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png" />

<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
<!-- Bootstrap -->
<link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous" />


<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/all.min.css" integrity="sha256-nAmazAk6vS34Xqo0BSrTb+abbtFlgsFK7NKSi6o7Y78=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/v4-shims.min.css" integrity="sha256-6qHlizsOWFskGlwVOKuns+D1nB6ssZrHQrNj1wGplHc=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script>

<!-- headroom.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/headroom.min.js" integrity="sha256-DJFC1kqIhelURkuza0AvYal5RxMtpzLjFhsnVIeuk+U=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>




<meta property="og:title" content="Model averaging/weighting via stacking or pseudo-BMA weighting — loo_model_weights" />
<meta property="og:description" content="Model averaging via stacking of predictive distributions, pseudo-BMA
weighting or pseudo-BMA+ weighting with the Bayesian bootstrap. See Yao et
al. (2018) and  Vehtari, Gelman, and Gabry (2017a,2017b) for background." />
<meta property="og:image" content="https://mc-stan.org/loo/logo.png" />
<meta name="twitter:card" content="summary" />




<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->



  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">loo</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">2.2.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../articles/index.html">Vignettes</a>
</li>
<li>
  <a href="../reference/index.html">Functions</a>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Other Packages
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="https://mc-stan.org/rstan">rstan</a>
    </li>
    <li>
      <a href="https://mc-stan.org/cmdstanr">cmdstanr</a>
    </li>
    <li>
      <a href="https://mc-stan.org/rstanarm">rstanarm</a>
    </li>
    <li>
      <a href="https://mc-stan.org/bayesplot">bayesplot</a>
    </li>
    <li>
      <a href="https://mc-stan.org/shinystan">shinystan</a>
    </li>
    <li>
      <a href="https://mc-stan.org/projpred">projpred</a>
    </li>
    <li>
      <a href="https://mc-stan.org/rstantools">rstantools</a>
    </li>
  </ul>
</li>
<li>
  <a href="https://mc-stan.org">Stan</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://twitter.com/mcmc_stan">
    <span class="fa fa-twitter"></span>
     
  </a>
</li>
<li>
  <a href="https://github.com/stan-dev/loo">
    <span class="fa fa-github"></span>
     
  </a>
</li>
<li>
  <a href="https://discourse.mc-stan.org/">
    <span class="fa fa-users"></span>
     
  </a>
</li>
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Model averaging/weighting via stacking or pseudo-BMA weighting</h1>
    
    <div class="hidden name"><code>loo_model_weights.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>Model averaging via stacking of predictive distributions, pseudo-BMA
weighting or pseudo-BMA+ weighting with the Bayesian bootstrap. See Yao et
al. (2018) and  Vehtari, Gelman, and Gabry (2017a,2017b) for background.</p>
    </div>

    <pre class="usage"><span class='fu'>loo_model_weights</span>(<span class='no'>x</span>, <span class='no'>...</span>)

<span class='co'># S3 method for default</span>
<span class='fu'>loo_model_weights</span>(
  <span class='no'>x</span>,
  <span class='no'>...</span>,
  <span class='kw'>method</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='st'>"stacking"</span>, <span class='st'>"pseudobma"</span>),
  <span class='kw'>optim_method</span> <span class='kw'>=</span> <span class='st'>"BFGS"</span>,
  <span class='kw'>optim_control</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span>(),
  <span class='kw'>BB</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>,
  <span class='kw'>BB_n</span> <span class='kw'>=</span> <span class='fl'>1000</span>,
  <span class='kw'>alpha</span> <span class='kw'>=</span> <span class='fl'>1</span>,
  <span class='kw'>r_eff_list</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>cores</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/options.html'>getOption</a></span>(<span class='st'>"mc.cores"</span>, <span class='fl'>1</span>)
)

<span class='fu'>stacking_weights</span>(<span class='no'>lpd_point</span>, <span class='kw'>optim_method</span> <span class='kw'>=</span> <span class='st'>"BFGS"</span>, <span class='kw'>optim_control</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span>())

<span class='fu'>pseudobma_weights</span>(<span class='no'>lpd_point</span>, <span class='kw'>BB</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>, <span class='kw'>BB_n</span> <span class='kw'>=</span> <span class='fl'>1000</span>, <span class='kw'>alpha</span> <span class='kw'>=</span> <span class='fl'>1</span>)</pre>

    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>x</th>
      <td><p>A list of pointwise log-likelihood matrices or <code>"psis_loo"</code> objects
(objects returned by <code><a href='loo.html'>loo()</a></code>), one for each model. Each
matrix/object should have dimensions \(S\) by \(N\), where \(S\) is
the size of the posterior sample (with all chains merged) and \(N\) is
the number of data points. If <code>x</code> is a list of log-likelihood matrices
then <code><a href='loo.html'>loo()</a></code> is called internally on each matrix. Currently the
<code>loo_model_weights()</code> function is not implemented to be used with
results from K-fold CV, but you can still obtain weights using K-fold CV
results by calling the <code>stacking_weights()</code> function directly.</p></td>
    </tr>
    <tr>
      <th>...</th>
      <td><p>Unused, except for the generic to pass arguments to individual
methods.</p></td>
    </tr>
    <tr>
      <th>method</th>
      <td><p>Either <code>"stacking"</code> (the default) or <code>"pseudobma"</code>, indicating which method
to use for obtaining the weights. <code>"stacking"</code> refers to stacking of
predictive distributions and  <code>"pseudobma"</code> refers to pseudo-BMA+ weighting
(or plain pseudo-BMA weighting if argument <code>BB</code> is <code>FALSE</code>).</p></td>
    </tr>
    <tr>
      <th>optim_method</th>
      <td><p>If <code>method="stacking"</code>, a string passed to the <code>method</code>
argument of <code><a href='https://rdrr.io/r/stats/constrOptim.html'>stats::constrOptim()</a></code> to specify the optimization algorithm.
The default is <code>optim_method="BFGS"</code>, but other options are available (see
<code><a href='https://rdrr.io/r/stats/optim.html'>stats::optim()</a></code>).</p></td>
    </tr>
    <tr>
      <th>optim_control</th>
      <td><p>If <code>method="stacking"</code>, a list of control parameters for
optimization passed to the <code>control</code> argument of <code><a href='https://rdrr.io/r/stats/constrOptim.html'>stats::constrOptim()</a></code>.</p></td>
    </tr>
    <tr>
      <th>BB</th>
      <td><p>Logical used when <code>"method"</code>=<code>"pseudobma"</code>. If
<code>TRUE</code> (the default), the Bayesian bootstrap will be used to adjust
the pseudo-BMA weighting, which is called pseudo-BMA+ weighting. It helps
regularize the weight away from 0 and 1, so as to reduce the variance.</p></td>
    </tr>
    <tr>
      <th>BB_n</th>
      <td><p>For pseudo-BMA+ weighting only, the number of samples to use for
the Bayesian bootstrap. The default is <code>BB_n=1000</code>.</p></td>
    </tr>
    <tr>
      <th>alpha</th>
      <td><p>Positive scalar shape parameter in the Dirichlet distribution
used for the Bayesian bootstrap. The default is <code>alpha=1</code>, which
corresponds to a uniform distribution on the simplex space.</p></td>
    </tr>
    <tr>
      <th>r_eff_list</th>
      <td><p>Optionally, a list of relative effective sample size
estimates for the likelihood <code>(exp(log_lik))</code> of each observation in
each model. See <code><a href='psis.html'>psis()</a></code> and  <code><a href='relative_eff.html'>relative_eff()</a></code> helper
function for computing <code>r_eff</code>. If <code>x</code> is a list of <code>"psis_loo"</code>
objects then <code>r_eff_list</code> is ignored.</p></td>
    </tr>
    <tr>
      <th>cores</th>
      <td><p>The number of cores to use for parallelization. This defaults to
the option <code>mc.cores</code> which can be set for an entire R session by
<code><a href='https://rdrr.io/r/base/options.html'>options(mc.cores = NUMBER)</a></code>. The old option <code>loo.cores</code> is now
deprecated but will be given precedence over <code>mc.cores</code> until
<code>loo.cores</code> is removed in a future release. <strong>As of version
2.0.0 the default is now 1 core if <code>mc.cores</code> is not set</strong>, but we
recommend using as many (or close to as many) cores as possible.</p><ul>
<li><p>Note for Windows 10 users: it is <strong>strongly</strong>
<a href='https://github.com/stan-dev/loo/issues/94'>recommended</a> to avoid using
the <code>.Rprofile</code> file to set <code>mc.cores</code> (using the <code>cores</code> argument or
setting <code>mc.cores</code> interactively or in a script is fine).</p></li>
</ul></td>
    </tr>
    <tr>
      <th>lpd_point</th>
      <td><p>If calling <code>stacking_weights()</code> or <code>pseudobma_weights()</code>
directly, a matrix of pointwise leave-one-out (or K-fold) log likelihoods
evaluated for different models. It should be a \(N\) by \(K\)  matrix
where \(N\) is sample size and \(K\) is the number of models. Each
column corresponds to one model. These values can be calculated
approximately using <code><a href='loo.html'>loo()</a></code> or by running exact leave-one-out or K-fold
cross-validation.</p></td>
    </tr>
    </table>

    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>A numeric vector containing one weight for each model.</p>
    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p><code>loo_model_weights()</code> is a wrapper around the <code>stacking_weights()</code> and
<code>pseudobma_weights()</code> functions that implements stacking, pseudo-BMA, and
pseudo-BMA+ weighting for combining multiple predictive distributions. We can
use approximate or exact leave-one-out cross-validation (LOO-CV) or K-fold CV
to estimate the expected log predictive density (ELPD).</p>
<p>The stacking method (<code>method="stacking"</code>), which is the default for
<code>loo_model_weights()</code>, combines all models by maximizing the leave-one-out
predictive density of the combination distribution. That is, it finds the
optimal linear combining weights for maximizing the leave-one-out log score.</p>
<p>The pseudo-BMA method (<code>method="pseudobma"</code>) finds the relative weights
proportional to the ELPD of each model. However, when
<code>method="pseudobma"</code>, the default is to also use the Bayesian bootstrap
(<code>BB=TRUE</code>), which corresponds to the pseudo-BMA+ method. The Bayesian
bootstrap  takes into account the uncertainty of finite data points and
regularizes the weights away from the extremes of 0 and 1.</p>
<p>In general, we recommend stacking for averaging predictive distributions,
while pseudo-BMA+ can serve as a computationally easier alternative.</p>
    <h2 class="hasAnchor" id="references"><a class="anchor" href="#references"></a>References</h2>

    <p>Vehtari, A., Gelman, A., and Gabry, J. (2017a). Practical Bayesian model
evaluation using leave-one-out cross-validation and WAIC.
<em>Statistics and Computing</em>. 27(5), 1413--1432. doi:10.1007/s11222-016-9696-4
(<a href='http://link.springer.com/article/10.1007%2Fs11222-016-9696-4'>journal version</a>,
<a href='https://arxiv.org/abs/1507.04544'>preprint arXiv:1507.04544</a>).</p>
<p>Vehtari, A., Gelman, A., and Gabry, J. (2017b). Pareto smoothed
importance sampling.
<a href='https://arxiv.org/abs/1507.02646/'>preprint arXiv:1507.02646</a></p>
<p>Yao, Y., Vehtari, A., Simpson, D., and Gelman, A. (2018) Using
stacking to average Bayesian predictive distributions.
<em>Bayesian Analysis</em>, advance publication,  doi:10.1214/17-BA1091.
(<a href='https://projecteuclid.org/euclid.ba/1516093227'>online</a>).</p>
    <h2 class="hasAnchor" id="see-also"><a class="anchor" href="#see-also"></a>See also</h2>

    <div class='dont-index'>
<ul>
<li><p>The <strong>loo</strong> package <a href='https://mc-stan.org/loo/articles/'>vignettes</a>, particularly
<a href='https://mc-stan.org/loo/articles/loo2-weights.html'>Bayesian Stacking and Pseudo-BMA weights using the <strong>loo</strong> package</a>.</p></li>
<li><p><code><a href='loo.html'>loo()</a></code> for details on leave-one-out ELPD estimation.</p></li>
<li><p><code><a href='https://rdrr.io/r/stats/constrOptim.html'>constrOptim()</a></code> for the choice of optimization methods and control-parameters.</p></li>
<li><p><code><a href='relative_eff.html'>relative_eff()</a></code> for computing <code>r_eff</code>.</p></li>
</ul>
</div>

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'><span class='co'># \dontrun{</span>
<span class='co'>### Demonstrating usage after fitting models with RStan</span>
<span class='fu'><a href='https://rdrr.io/r/base/library.html'>library</a></span>(<span class='no'>rstan</span>)</div><div class='output co'>#&gt; <span class='message'>Loading required package: StanHeaders</span></div><div class='output co'>#&gt; <span class='message'>Loading required package: ggplot2</span></div><div class='output co'>#&gt; <span class='message'>rstan (Version 2.19.2, GitRev: 2e1f913d3ca3)</span></div><div class='output co'>#&gt; <span class='message'>For execution on a local, multicore CPU with excess RAM we recommend calling</span>
#&gt; <span class='message'>options(mc.cores = parallel::detectCores()).</span>
#&gt; <span class='message'>To avoid recompilation of unchanged Stan programs, we recommend calling</span>
#&gt; <span class='message'>rstan_options(auto_write = TRUE)</span></div><div class='input'>
<span class='co'># generate fake data from N(0,1).</span>
<span class='no'>N</span> <span class='kw'>&lt;-</span> <span class='fl'>100</span>
<span class='no'>y</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/Normal.html'>rnorm</a></span>(<span class='no'>N</span>, <span class='fl'>0</span>, <span class='fl'>1</span>)

<span class='co'># Suppose we have three models: N(-1, sigma), N(0.5, sigma) and N(0.6,sigma).</span>
<span class='no'>stan_code</span> <span class='kw'>&lt;-</span> <span class='st'>"
  data {
    int N;
    vector[N] y;
    real mu_fixed;
  }
  parameters {
    real&lt;lower=0&gt; sigma;
  }
  model {
    sigma ~ exponential(1);
    y ~ normal(mu_fixed, sigma);
  }
  generated quantities {
    vector[N] log_lik;
    for (n in 1:N) log_lik[n] = normal_lpdf(y[n]| mu_fixed, sigma);
  }"</span>

<span class='no'>mod</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/rstan/man/stan_model.html'>stan_model</a></span>(<span class='kw'>model_code</span> <span class='kw'>=</span> <span class='no'>stan_code</span>)
<span class='no'>fit1</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/rstan/man/stanmodel-method-sampling.html'>sampling</a></span>(<span class='no'>mod</span>, <span class='kw'>data</span><span class='kw'>=</span><span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span>(<span class='kw'>N</span><span class='kw'>=</span><span class='no'>N</span>, <span class='kw'>y</span><span class='kw'>=</span><span class='no'>y</span>, <span class='kw'>mu_fixed</span><span class='kw'>=</span>-<span class='fl'>1</span>))</div><div class='output co'>#&gt; 
#&gt; SAMPLING FOR MODEL '3357c2d5f7fa83a0237f870309913d65' NOW (CHAIN 1).
#&gt; Chain 1: 
#&gt; Chain 1: Gradient evaluation took 1e-05 seconds
#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds.
#&gt; Chain 1: Adjust your expectations accordingly!
#&gt; Chain 1: 
#&gt; Chain 1: 
#&gt; Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
#&gt; Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
#&gt; Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
#&gt; Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
#&gt; Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
#&gt; Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
#&gt; Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
#&gt; Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
#&gt; Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
#&gt; Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
#&gt; Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
#&gt; Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
#&gt; Chain 1: 
#&gt; Chain 1:  Elapsed Time: 0.013862 seconds (Warm-up)
#&gt; Chain 1:                0.012641 seconds (Sampling)
#&gt; Chain 1:                0.026503 seconds (Total)
#&gt; Chain 1: 
#&gt; 
#&gt; SAMPLING FOR MODEL '3357c2d5f7fa83a0237f870309913d65' NOW (CHAIN 2).
#&gt; Chain 2: 
#&gt; Chain 2: Gradient evaluation took 5e-06 seconds
#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.
#&gt; Chain 2: Adjust your expectations accordingly!
#&gt; Chain 2: 
#&gt; Chain 2: 
#&gt; Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
#&gt; Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
#&gt; Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
#&gt; Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
#&gt; Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
#&gt; Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
#&gt; Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
#&gt; Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
#&gt; Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
#&gt; Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
#&gt; Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
#&gt; Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
#&gt; Chain 2: 
#&gt; Chain 2:  Elapsed Time: 0.013443 seconds (Warm-up)
#&gt; Chain 2:                0.01388 seconds (Sampling)
#&gt; Chain 2:                0.027323 seconds (Total)
#&gt; Chain 2: 
#&gt; 
#&gt; SAMPLING FOR MODEL '3357c2d5f7fa83a0237f870309913d65' NOW (CHAIN 3).
#&gt; Chain 3: 
#&gt; Chain 3: Gradient evaluation took 5e-06 seconds
#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.
#&gt; Chain 3: Adjust your expectations accordingly!
#&gt; Chain 3: 
#&gt; Chain 3: 
#&gt; Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
#&gt; Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
#&gt; Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
#&gt; Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
#&gt; Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
#&gt; Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
#&gt; Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
#&gt; Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
#&gt; Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
#&gt; Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
#&gt; Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
#&gt; Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
#&gt; Chain 3: 
#&gt; Chain 3:  Elapsed Time: 0.014582 seconds (Warm-up)
#&gt; Chain 3:                0.012858 seconds (Sampling)
#&gt; Chain 3:                0.02744 seconds (Total)
#&gt; Chain 3: 
#&gt; 
#&gt; SAMPLING FOR MODEL '3357c2d5f7fa83a0237f870309913d65' NOW (CHAIN 4).
#&gt; Chain 4: 
#&gt; Chain 4: Gradient evaluation took 7e-06 seconds
#&gt; Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.
#&gt; Chain 4: Adjust your expectations accordingly!
#&gt; Chain 4: 
#&gt; Chain 4: 
#&gt; Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
#&gt; Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
#&gt; Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
#&gt; Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
#&gt; Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
#&gt; Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
#&gt; Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
#&gt; Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
#&gt; Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
#&gt; Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
#&gt; Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
#&gt; Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
#&gt; Chain 4: 
#&gt; Chain 4:  Elapsed Time: 0.016352 seconds (Warm-up)
#&gt; Chain 4:                0.014264 seconds (Sampling)
#&gt; Chain 4:                0.030616 seconds (Total)
#&gt; Chain 4: </div><div class='input'><span class='no'>fit2</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/rstan/man/stanmodel-method-sampling.html'>sampling</a></span>(<span class='no'>mod</span>, <span class='kw'>data</span><span class='kw'>=</span><span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span>(<span class='kw'>N</span><span class='kw'>=</span><span class='no'>N</span>, <span class='kw'>y</span><span class='kw'>=</span><span class='no'>y</span>, <span class='kw'>mu_fixed</span><span class='kw'>=</span><span class='fl'>0.5</span>))</div><div class='output co'>#&gt; 
#&gt; SAMPLING FOR MODEL '3357c2d5f7fa83a0237f870309913d65' NOW (CHAIN 1).
#&gt; Chain 1: 
#&gt; Chain 1: Gradient evaluation took 6e-06 seconds
#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.06 seconds.
#&gt; Chain 1: Adjust your expectations accordingly!
#&gt; Chain 1: 
#&gt; Chain 1: 
#&gt; Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
#&gt; Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
#&gt; Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
#&gt; Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
#&gt; Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
#&gt; Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
#&gt; Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
#&gt; Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
#&gt; Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
#&gt; Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
#&gt; Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
#&gt; Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
#&gt; Chain 1: 
#&gt; Chain 1:  Elapsed Time: 0.016827 seconds (Warm-up)
#&gt; Chain 1:                0.014423 seconds (Sampling)
#&gt; Chain 1:                0.03125 seconds (Total)
#&gt; Chain 1: 
#&gt; 
#&gt; SAMPLING FOR MODEL '3357c2d5f7fa83a0237f870309913d65' NOW (CHAIN 2).
#&gt; Chain 2: 
#&gt; Chain 2: Gradient evaluation took 8e-06 seconds
#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds.
#&gt; Chain 2: Adjust your expectations accordingly!
#&gt; Chain 2: 
#&gt; Chain 2: 
#&gt; Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
#&gt; Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
#&gt; Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
#&gt; Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
#&gt; Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
#&gt; Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
#&gt; Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
#&gt; Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
#&gt; Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
#&gt; Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
#&gt; Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
#&gt; Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
#&gt; Chain 2: 
#&gt; Chain 2:  Elapsed Time: 0.016598 seconds (Warm-up)
#&gt; Chain 2:                0.012806 seconds (Sampling)
#&gt; Chain 2:                0.029404 seconds (Total)
#&gt; Chain 2: 
#&gt; 
#&gt; SAMPLING FOR MODEL '3357c2d5f7fa83a0237f870309913d65' NOW (CHAIN 3).
#&gt; Chain 3: 
#&gt; Chain 3: Gradient evaluation took 3e-06 seconds
#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.03 seconds.
#&gt; Chain 3: Adjust your expectations accordingly!
#&gt; Chain 3: 
#&gt; Chain 3: 
#&gt; Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
#&gt; Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
#&gt; Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
#&gt; Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
#&gt; Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
#&gt; Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
#&gt; Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
#&gt; Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
#&gt; Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
#&gt; Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
#&gt; Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
#&gt; Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
#&gt; Chain 3: 
#&gt; Chain 3:  Elapsed Time: 0.013477 seconds (Warm-up)
#&gt; Chain 3:                0.016096 seconds (Sampling)
#&gt; Chain 3:                0.029573 seconds (Total)
#&gt; Chain 3: 
#&gt; 
#&gt; SAMPLING FOR MODEL '3357c2d5f7fa83a0237f870309913d65' NOW (CHAIN 4).
#&gt; Chain 4: 
#&gt; Chain 4: Gradient evaluation took 4e-06 seconds
#&gt; Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds.
#&gt; Chain 4: Adjust your expectations accordingly!
#&gt; Chain 4: 
#&gt; Chain 4: 
#&gt; Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
#&gt; Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
#&gt; Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
#&gt; Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
#&gt; Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
#&gt; Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
#&gt; Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
#&gt; Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
#&gt; Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
#&gt; Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
#&gt; Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
#&gt; Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
#&gt; Chain 4: 
#&gt; Chain 4:  Elapsed Time: 0.013832 seconds (Warm-up)
#&gt; Chain 4:                0.01277 seconds (Sampling)
#&gt; Chain 4:                0.026602 seconds (Total)
#&gt; Chain 4: </div><div class='input'><span class='no'>fit3</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/rstan/man/stanmodel-method-sampling.html'>sampling</a></span>(<span class='no'>mod</span>, <span class='kw'>data</span><span class='kw'>=</span><span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span>(<span class='kw'>N</span><span class='kw'>=</span><span class='no'>N</span>, <span class='kw'>y</span><span class='kw'>=</span><span class='no'>y</span>, <span class='kw'>mu_fixed</span><span class='kw'>=</span><span class='fl'>0.6</span>))</div><div class='output co'>#&gt; 
#&gt; SAMPLING FOR MODEL '3357c2d5f7fa83a0237f870309913d65' NOW (CHAIN 1).
#&gt; Chain 1: 
#&gt; Chain 1: Gradient evaluation took 6e-06 seconds
#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.06 seconds.
#&gt; Chain 1: Adjust your expectations accordingly!
#&gt; Chain 1: 
#&gt; Chain 1: 
#&gt; Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
#&gt; Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
#&gt; Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
#&gt; Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
#&gt; Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
#&gt; Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
#&gt; Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
#&gt; Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
#&gt; Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
#&gt; Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
#&gt; Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
#&gt; Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
#&gt; Chain 1: 
#&gt; Chain 1:  Elapsed Time: 0.017477 seconds (Warm-up)
#&gt; Chain 1:                0.014685 seconds (Sampling)
#&gt; Chain 1:                0.032162 seconds (Total)
#&gt; Chain 1: 
#&gt; 
#&gt; SAMPLING FOR MODEL '3357c2d5f7fa83a0237f870309913d65' NOW (CHAIN 2).
#&gt; Chain 2: 
#&gt; Chain 2: Gradient evaluation took 8e-06 seconds
#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds.
#&gt; Chain 2: Adjust your expectations accordingly!
#&gt; Chain 2: 
#&gt; Chain 2: 
#&gt; Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
#&gt; Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
#&gt; Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
#&gt; Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
#&gt; Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
#&gt; Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
#&gt; Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
#&gt; Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
#&gt; Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
#&gt; Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
#&gt; Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
#&gt; Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
#&gt; Chain 2: 
#&gt; Chain 2:  Elapsed Time: 0.016969 seconds (Warm-up)
#&gt; Chain 2:                0.013978 seconds (Sampling)
#&gt; Chain 2:                0.030947 seconds (Total)
#&gt; Chain 2: 
#&gt; 
#&gt; SAMPLING FOR MODEL '3357c2d5f7fa83a0237f870309913d65' NOW (CHAIN 3).
#&gt; Chain 3: 
#&gt; Chain 3: Gradient evaluation took 3e-06 seconds
#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.03 seconds.
#&gt; Chain 3: Adjust your expectations accordingly!
#&gt; Chain 3: 
#&gt; Chain 3: 
#&gt; Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
#&gt; Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
#&gt; Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
#&gt; Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
#&gt; Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
#&gt; Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
#&gt; Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
#&gt; Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
#&gt; Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
#&gt; Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
#&gt; Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
#&gt; Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
#&gt; Chain 3: 
#&gt; Chain 3:  Elapsed Time: 0.015595 seconds (Warm-up)
#&gt; Chain 3:                0.014561 seconds (Sampling)
#&gt; Chain 3:                0.030156 seconds (Total)
#&gt; Chain 3: 
#&gt; 
#&gt; SAMPLING FOR MODEL '3357c2d5f7fa83a0237f870309913d65' NOW (CHAIN 4).
#&gt; Chain 4: 
#&gt; Chain 4: Gradient evaluation took 4e-06 seconds
#&gt; Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds.
#&gt; Chain 4: Adjust your expectations accordingly!
#&gt; Chain 4: 
#&gt; Chain 4: 
#&gt; Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
#&gt; Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
#&gt; Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
#&gt; Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
#&gt; Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
#&gt; Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
#&gt; Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
#&gt; Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
#&gt; Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
#&gt; Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
#&gt; Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
#&gt; Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
#&gt; Chain 4: 
#&gt; Chain 4:  Elapsed Time: 0.01587 seconds (Warm-up)
#&gt; Chain 4:                0.015723 seconds (Sampling)
#&gt; Chain 4:                0.031593 seconds (Total)
#&gt; Chain 4: </div><div class='input'><span class='no'>model_list</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span>(<span class='no'>fit1</span>, <span class='no'>fit2</span>, <span class='no'>fit3</span>)
<span class='no'>log_lik_list</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/lapply.html'>lapply</a></span>(<span class='no'>model_list</span>, <span class='no'>extract_log_lik</span>)

<span class='co'># optional but recommended</span>
<span class='no'>r_eff_list</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/lapply.html'>lapply</a></span>(<span class='no'>model_list</span>, <span class='kw'>function</span>(<span class='no'>x</span>) {
  <span class='no'>ll_array</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='extract_log_lik.html'>extract_log_lik</a></span>(<span class='no'>x</span>, <span class='kw'>merge_chains</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>)
  <span class='fu'><a href='relative_eff.html'>relative_eff</a></span>(<span class='fu'><a href='https://rdrr.io/r/base/Log.html'>exp</a></span>(<span class='no'>ll_array</span>))
})

<span class='co'># stacking method:</span>
<span class='no'>wts1</span> <span class='kw'>&lt;-</span> <span class='fu'>loo_model_weights</span>(
  <span class='no'>log_lik_list</span>,
  <span class='kw'>method</span> <span class='kw'>=</span> <span class='st'>"stacking"</span>,
  <span class='kw'>r_eff_list</span> <span class='kw'>=</span> <span class='no'>r_eff_list</span>,
  <span class='kw'>optim_control</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span>(<span class='kw'>reltol</span><span class='kw'>=</span><span class='fl'>1e-10</span>)
)
<span class='fu'><a href='https://rdrr.io/r/base/print.html'>print</a></span>(<span class='no'>wts1</span>)</div><div class='output co'>#&gt; Method: stacking
#&gt; ------
#&gt;        weight
#&gt; model1 0.068 
#&gt; model2 0.932 
#&gt; model3 0.000 </div><div class='input'>
<span class='co'># can also pass a list of psis_loo objects to avoid recomputing loo</span>
<span class='no'>loo_list</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/lapply.html'>lapply</a></span>(<span class='fl'>1</span>:<span class='fu'><a href='https://rdrr.io/r/base/length.html'>length</a></span>(<span class='no'>log_lik_list</span>), <span class='kw'>function</span>(<span class='no'>j</span>) {
  <span class='fu'><a href='loo.html'>loo</a></span>(<span class='no'>log_lik_list</span><span class='kw'>[[</span><span class='no'>j</span>]], <span class='kw'>r_eff</span> <span class='kw'>=</span> <span class='no'>r_eff_list</span><span class='kw'>[[</span><span class='no'>j</span>]])
})

<span class='no'>wts2</span> <span class='kw'>&lt;-</span> <span class='fu'>loo_model_weights</span>(
  <span class='no'>loo_list</span>,
  <span class='kw'>method</span> <span class='kw'>=</span> <span class='st'>"stacking"</span>,
  <span class='kw'>optim_control</span> <span class='kw'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span>(<span class='kw'>reltol</span><span class='kw'>=</span><span class='fl'>1e-10</span>)
)
<span class='fu'><a href='https://rdrr.io/r/base/all.equal.html'>all.equal</a></span>(<span class='no'>wts1</span>, <span class='no'>wts2</span>)</div><div class='output co'>#&gt; [1] TRUE</div><div class='input'>

<span class='co'># pseudo-BMA+ method:</span>
<span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span>(<span class='fl'>1414</span>)
<span class='fu'>loo_model_weights</span>(<span class='no'>loo_list</span>, <span class='kw'>method</span> <span class='kw'>=</span> <span class='st'>"pseudobma"</span>)</div><div class='output co'>#&gt; Method: pseudo-BMA+ with Bayesian bootstrap
#&gt; ------
#&gt;        weight
#&gt; model1 0.000 
#&gt; model2 0.961 
#&gt; model3 0.038 </div><div class='input'>
<span class='co'># pseudo-BMA method (set BB = FALSE):</span>
<span class='fu'>loo_model_weights</span>(<span class='no'>loo_list</span>, <span class='kw'>method</span> <span class='kw'>=</span> <span class='st'>"pseudobma"</span>, <span class='kw'>BB</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>)</div><div class='output co'>#&gt; Method: pseudo-BMA
#&gt; ------
#&gt;        weight
#&gt; model1 0.000 
#&gt; model2 0.970 
#&gt; model3 0.030 </div><div class='input'>
<span class='co'># calling stacking_weights or pseudobma_weights directly</span>
<span class='no'>lpd1</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='loo.html'>loo</a></span>(<span class='no'>log_lik_list</span><span class='kw'>[[</span><span class='fl'>1</span>]], <span class='kw'>r_eff</span> <span class='kw'>=</span> <span class='no'>r_eff_list</span><span class='kw'>[[</span><span class='fl'>1</span>]])$<span class='no'>pointwise</span>[,<span class='fl'>1</span>]
<span class='no'>lpd2</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='loo.html'>loo</a></span>(<span class='no'>log_lik_list</span><span class='kw'>[[</span><span class='fl'>2</span>]], <span class='kw'>r_eff</span> <span class='kw'>=</span> <span class='no'>r_eff_list</span><span class='kw'>[[</span><span class='fl'>2</span>]])$<span class='no'>pointwise</span>[,<span class='fl'>1</span>]
<span class='no'>lpd3</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='loo.html'>loo</a></span>(<span class='no'>log_lik_list</span><span class='kw'>[[</span><span class='fl'>3</span>]], <span class='kw'>r_eff</span> <span class='kw'>=</span> <span class='no'>r_eff_list</span><span class='kw'>[[</span><span class='fl'>3</span>]])$<span class='no'>pointwise</span>[,<span class='fl'>1</span>]
<span class='fu'>stacking_weights</span>(<span class='fu'><a href='https://rdrr.io/r/base/cbind.html'>cbind</a></span>(<span class='no'>lpd1</span>, <span class='no'>lpd2</span>, <span class='no'>lpd3</span>))</div><div class='output co'>#&gt; Method: stacking
#&gt; ------
#&gt;        weight
#&gt; model1 0.068 
#&gt; model2 0.932 
#&gt; model3 0.000 </div><div class='input'><span class='fu'>pseudobma_weights</span>(<span class='fu'><a href='https://rdrr.io/r/base/cbind.html'>cbind</a></span>(<span class='no'>lpd1</span>, <span class='no'>lpd2</span>, <span class='no'>lpd3</span>))</div><div class='output co'>#&gt; Method: pseudo-BMA+ with Bayesian bootstrap
#&gt; ------
#&gt;        weight
#&gt; model1 0.001 
#&gt; model2 0.961 
#&gt; model3 0.038 </div><div class='input'><span class='fu'>pseudobma_weights</span>(<span class='fu'><a href='https://rdrr.io/r/base/cbind.html'>cbind</a></span>(<span class='no'>lpd1</span>, <span class='no'>lpd2</span>, <span class='no'>lpd3</span>), <span class='kw'>BB</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>)</div><div class='output co'>#&gt; Method: pseudo-BMA
#&gt; ------
#&gt;        weight
#&gt; model1 0.000 
#&gt; model2 0.970 
#&gt; model3 0.030 </div><div class='input'># }

</div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      <li><a href="#value">Value</a></li>
      <li><a href="#details">Details</a></li>
      <li><a href="#references">References</a></li>
      <li><a href="#see-also">See also</a></li>
      <li><a href="#examples">Examples</a></li>
    </ul>

  </div>
</div>


      <footer>
      <div class="copyright">
  <p>Developed by Aki Vehtari, Jonah Gabry, Mans Magnusson, Yuling Yao, Andrew Gelman.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.4.1.</p>
</div>

      </footer>
   </div>

  


  </body>
</html>


